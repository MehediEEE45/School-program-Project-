import cv2
import numpy as np
import mediapipe as mp
import time
import math
from cvzone.FaceDetectionModule import FaceDetector
#import pyfirmata  # Commented out because servo control disabled

# # === Change this to your Arduino COM port ===
# port = 'COM7'  # e.g. 'COM3', 'COM5' etc.

# try:
#     board = pyfirmata.Arduino(port)
# except Exception as e:
#     print(f"Error connecting to Arduino on port {port}: {e}")
#     exit()

# servo_pinX = board.get_pin('d:9:s')
# servo_pinY = board.get_pin('d:10:s')

cap = cv2.VideoCapture(0)
ws, hs = 1280, 720
cap.set(3, ws)
cap.set(4, hs)

detector = FaceDetector()
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1)
mp_draw = mp.solutions.drawing_utils

mode = "face"
alpha = 0.2
prev_x, prev_y = ws // 2, hs // 2
prev_time = time.time()
prev_real_x, prev_real_y = 0, 0
ref_distance_cm = 50
ref_size = None
pixel_per_cm = None

servo_active = False

print("â–¶ Press 1: Face tracking | 2: Hand tracking | c: Calibrate | s: Start servo | q: Quit")

while True:
    success, img = cap.read()
    if not success:
        print("Cannot read from camera")
        break
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    current_time = time.time()
    distance_cm = None
    speed_mps = 0
    servoX, servoY = 90, 90  # default servo middle position

    # Draw crosshair in the middle
    cv2.line(img, (ws // 2, 0), (ws // 2, hs), (180, 180, 180), 1)
    cv2.line(img, (0, hs // 2), (ws, hs // 2), (180, 180, 180), 1)

    if mode == "face":
        img, faces = detector.findFaces(img, draw=True)
        if faces:
            fx, fy = faces[0]["center"]
            w = faces[0]["bbox"][2]

            cx = int(alpha * fx + (1 - alpha) * prev_x)
            cy = int(alpha * fy + (1 - alpha) * prev_y)
            prev_x, prev_y = cx, cy

            if ref_size and w > 0:
                distance_cm = (ref_size * ref_distance_cm) / w
                pixel_per_cm = w / ref_distance_cm

            if pixel_per_cm:
                real_x = cx / pixel_per_cm
                real_y = cy / pixel_per_cm
                dx = real_x - prev_real_x
                dy = real_y - prev_real_y
                dist = math.sqrt(dx ** 2 + dy ** 2)
                dt = current_time - prev_time
                speed_mps = (dist / 100) / dt if dt > 0 else 0
                prev_real_x, prev_real_y = real_x, real_y
                prev_time = current_time

            servoX = np.interp(cx, [0, ws], [0, 180])
            servoY = np.interp(cy, [0, hs], [180, 0])

            cv2.putText(img, f'FACE LOCKED', (900, 50),
                        cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)
            cv2.circle(img, (cx, cy), 15, (0, 0, 255), cv2.FILLED)

    elif mode == "hand":
        result = hands.process(img_rgb)
        if result.multi_hand_landmarks:
            hand_landmarks = result.multi_hand_landmarks[0]
            lm = hand_landmarks.landmark[0]
            cx_raw = int(lm.x * ws)
            cy_raw = int(lm.y * hs)

            cx = int(alpha * cx_raw + (1 - alpha) * prev_x)
            cy = int(alpha * cy_raw + (1 - alpha) * prev_y)
            prev_x, prev_y = cx, cy

            x_list = [int(pt.x * ws) for pt in hand_landmarks.landmark]
            y_list = [int(pt.y * hs) for pt in hand_landmarks.landmark]
            bbox_w = max(x_list) - min(x_list)
            bbox_h = max(y_list) - min(y_list)
            size = (bbox_w + bbox_h) / 2

            if ref_size and size > 0:
                distance_cm = (ref_size * ref_distance_cm) / size
                pixel_per_cm = size / ref_distance_cm

            if pixel_per_cm:
                real_x = cx / pixel_per_cm
                real_y = cy / pixel_per_cm
                dx = real_x - prev_real_x
                dy = real_y - prev_real_y
                dist = math.sqrt(dx ** 2 + dy ** 2)
                dt = current_time - prev_time
                speed_mps = (dist / 100) / dt if dt > 0 else 0
                prev_real_x, prev_real_y = real_x, real_y
                prev_time = current_time

            servoX = np.interp(cx, [0, ws], [0, 180])
            servoY = np.interp(cy, [0, hs], [180, 0])

            mp_draw.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            cv2.circle(img, (cx, cy), 15, (0, 255, 0), cv2.FILLED)
            cv2.putText(img, f'HAND LOCKED', (900, 50),
                        cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 255), 3)

    # # Send servo commands only if servo_active is True
    # if servo_active:
    #     print(f"Servo moving to X: {servoX:.1f}, Y: {servoY:.1f}")  # DEBUG print
    #     servo_pinX.write(servoX)
    #     servo_pinY.write(servoY)

    cv2.putText(img, f'MODE: {mode.upper()}', (50, 40),
                cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)
    cv2.putText(img, f'X: {prev_x}  Y: {prev_y}', (50, 80),
                cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 0), 2)
    if distance_cm:
        cv2.putText(img, f'Distance: {distance_cm:.1f} cm', (50, 120),
                    cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)
    cv2.putText(img, f'Speed: {speed_mps:.2f} m/s', (50, 160),
                cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 255), 2)
    cv2.putText(img, f'Servo Active: {"YES" if servo_active else "NO"}', (50, 200),
                cv2.FONT_HERSHEY_PLAIN, 2, (0, 200, 200), 2)

    cv2.imshow("Tracker", img)

    key = cv2.waitKey(1) & 0xFF

    if key == ord('1'):
        mode = "face"
        print("ðŸ“· Face tracking mode enabled")
    elif key == ord('2'):
        mode = "hand"
        print("âœ‹ Hand tracking mode enabled")
    elif key == ord('c'):
        if mode == "face" and 'faces' in locals() and faces:
            ref_size = faces[0]["bbox"][2]
            print(f"âœ… Face calibrated at {ref_distance_cm} cm with width {ref_size}")
        elif mode == "hand" and result.multi_hand_landmarks:
            ref_size = size
            print(f"âœ… Hand calibrated at {ref_distance_cm} cm with size {ref_size}")
    elif key == ord('s'):
        servo_active = True
        print("â–¶ Servo control started")
    elif key == ord('q'):
        print("Exiting program")
        break

cap.release()
cv2.destroyAllWindows()
# board.exit()  # Commented out since board is not initialized
